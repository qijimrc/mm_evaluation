# Configure the data paths for evaluation

level_1:

  VQAv2:
    # annotation files
    anns_paths: /nxchinamobile2/shared/instruction_data/evaluation/vqav2_sampled.json
    # directory of images
    img_dir: /nxchinamobile2/shared/img_datasets/MSCOCO/MSCOCO2014/val2014
    # which metrics to be used for measurements, supporting [vqa_acc, ...]
    metrics: [vqa_acc, gpt35_metric]
    # whether to be used for current evaluation
    eval: True

  # visual7w:
  #   anns_paths: [path/to/annotations]
  #   img_dir: path/to/images
  #   metrics: [vqa_acc, gpt3.5]
  #   eval: True

# level_2:

#   ok_vqa:
#     anns_paths: [path/to/annotations]
#     img_dir: path/to/images
#     metrics: [vqa_acc, gpt3.5]
#     eval: True

level_3:

  HalVQA:
    # description: Test the discriminative ability of the model for objects and attribuvisualglm-6btes
    anns_paths: /nxchinamobile2/shared/img_datasets/hal_val_sample/hallucination_test_clean.csv
    img_dir: /nxchinamobile2/shared/img_datasets/hal_val_sample/evaluate_sample
    metrics: [hal_acc]
    eval: True