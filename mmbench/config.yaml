# Configure the data paths for evaluation

level_1:

  VQAv2:
    # annotation files
    anns_paths: /nxchinamobile2/shared/instruction_data/evaluation/vqav2_sampled.json
    # directory of images
    img_dir: /nxchinamobile2/shared/img_datasets/MSCOCO/MSCOCO2014/val2014
    # which metrics to be used for measurements, supporting [vqa_acc, ...]
    metrics: [vqa_acc, gpt35_metric]
    # whether to be used for current evaluation
    eval: True

  Flickr30kEntities:
    anns_paths: /nxchinamobile2/shared/instruction_data/evaluation/flickr3kent_sampled.jsonl
    img_dir: /nxchinamobile2/shared/img_datasets/shikra/flickr30k-images
    eval: true
    metrics: [grounding]
    n_samples: 500
    seed: 71

  # visual7w:
  #   anns_paths: [path/to/annotations]
  #   img_dir: path/to/images
  #   metrics: [vqa_acc, gpt3.5]
  #   eval: True

# level_2:

#   ok_vqa:
#     anns_paths: [path/to/annotations]
#     img_dir: path/to/images
#     metrics: [vqa_acc, gpt3.5]
#     eval: True

# level_3:

#   HalVQA:
#     # description: Test the discriminative ability of the model for objects and attribuvisualglm-6btes
#     anns_paths: /nxchinamobile2/shared/img_datasets/hal_val_finetuned/hallucination_finetuned_small.csv
#     img_dir: /nxchinamobile2/shared/img_datasets/hal_val_sample/evaluate_sample
#     metrics: [hal_acc]
#     eval: True