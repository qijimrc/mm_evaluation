# Configure the task for evaluation

server_addr: wulan

home_env:
  wulan:
    data_home: /mnt/shared/img_datasets/mmbench_datasets/processed
  zhongwei:
    data_home: /share/img_datasets/mmbench_datasets/processed_mmbench_20231120
  zhongwei2:
    data_home: /zhipu-data/img_datasets/mmbench_datasets/processed_mmbench_20231120

tasks:
  level_1:
    Infer:
      data:
        test_data: /zhipu-data/img_datasets/cleaned_rlhf/raw_data/20231218###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 512
        max_target_length: 256
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 2000
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_iters: 100
        eval_interval: 500
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8

    ScienceQA:
      data:
        train_data: ScienceQA/train###train
        valid_data: ScienceQA/val###val
        test_data: ScienceQA/test###test
      need_finetune: true
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 1000
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_iters: 100
        eval_interval: 500
        eval_batch_size: 1
        top_k: 10
        top_p: 0.4
        temperature: 0.8
    
    Visual7W:
      data:
        train_data: Visual7W/train###train
        valid_data: Visual7W/val###val
        test_data: Visual7W/test###test
      need_finetune: true
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 1000
      finetune_params:
        log_interval: 20
        train_iters: 5000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 1000
        split: "1"
      eval_params:
        eval_iters: 200
        eval_interval: 1000
        eval_batch_size: 1
        top_k: 10
        top_p: 0.4
        temperature: 0.8
    
    OCRVQA:
      data:
        train_data: OCR-VQA/train###train
        valid_data: OCR-VQA/val###val
        test_data: OCR-VQA/test###test
      need_finetune: true
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
      finetune_params:
        log_interval: 20
        train_iters: 5000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 1000
        split: "1"
      eval_params:
        eval_iters: 200
        eval_interval: 1000
        eval_batch_size: 1
        top_k: 10
        top_p: 0.4
        temperature: 0.8
    
    TDIUC:
      data:
        train_data: TDIUC/train###train
        test_data: TDIUC/val###test
      need_finetune: true
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
      finetune_params:
        log_interval: 20
        train_iters: 5000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 1000
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 10
        top_p: 0.4
        temperature: 0.8
    
    TextVQA:
      data:
        train_data: TextVQA/train###train
        test_data: TextVQA/val###test
        upload_data: [TextVQA/test]
      need_finetune: true
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8
      
    GQA:
      data:
        train_data: GQA/train###train
        valid_data: GQA/val###val
        test_data: GQA/testdev_balanced###test
      need_finetune: true
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
      finetune_params:
        log_interval: 20
        train_iters: 10000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 1000
        split: "1"
      eval_params:
        eval_iters: 200
        eval_interval: 1000
        eval_batch_size: 1
        top_k: 10
        top_p: 0.4
        temperature: 0.8
    
    NoCaps:
      data:
        test_data: NoCaps/val###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 256
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 1000
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8
    
    VQAv2:
      data:
        train_data: VQAV2/train###train
        test_data: VQAV2/val###test
        upload_data: [VQAV2/test]
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8
    
    COCO:
      data:
        train_data: COCO/train###train
        valid_data: COCO/val###val
        test_data: COCO/val###test
      need_finetune: true
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 256
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8

    STVQA:
      data:
        train_data: STVQA/train###train
        upload_data: [STVQA/test_task_3]
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8

    FlickrCap:
      data:
        train_data: FlickrCap/train###train
        valid_data: FlickrCap/val###val
        test_data: FlickrCap/test###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 256
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8

    ChartQA:
      data:
        train_data: ChartQA/train###train
        valid_data: ChartQA/val###val
        test_data: ChartQA/test###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8

    RefCOCO:
      data:
        train_data: RefCOCO/train###train
        valid_data: RefCOCO/refcoco-val###val
        test_data: RefCOCO/test###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8

    DocVQA:
      data:
        train_data: DocVQA/train###train
        valid_data: DocVQA/val###val
        test_data: DocVQA/test###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8

    VizWizVQA:
      data:
        train_data: VizWiz-VQA/train###train
        valid_data: VizWiz-VQA/val###val
        test_data: VizWiz-VQA/test###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8
    
    TallyQA:
      data:
        train_data: TallyQA/train###train
        test_data: TallyQA/test###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8
    
  level_2:
    OKVQA:
      data:
        train_data: OK-VQA/train###train
        test_data: OK-VQA/val###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
        no_prompt: true
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8

  level_3:
    HalVQA:
      data:
        train_data: HalVQA/train###train
        test_data: HalVQA/test###test
      need_finetune: true
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_interval: 0
        block_size: 500
        eval_batch_size: 1
        top_k: 10
        top_p: 0.4
        temperature: 0.8
      
    TouchStone:
      data:
        test_data: TouchStone/test###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_iters: 100
        eval_interval: 500
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8
    
    TouchStoneChinese:
      data:
        test_data: TouchStone/test-zh###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 256
        max_target_length: 128
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
      finetune_params:
        log_interval: 20
        train_iters: 2000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 500
        split: "1"
      eval_params:
        eval_iters: 100
        eval_interval: 500
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8
    
    AlignMMBench:
      data:
        train_data: AlignMMBench/train###train
        valid_data: AlignMMBench/valid###valid
        test_data: AlignMMBench/test###test
      need_finetune: false
      need_evaluate: true
      data_params:
        max_source_length: 1024
        max_target_length: 512
        iterable_dataset: false
        train_data_load_mode: epoch_round
        block_size: 500
      finetune_params:
        log_interval: 20
        train_iters: 1000
        resume_dataloader: true
        lr_decay_style: cosine
        warmup: 0.02
        save_interval: 50
        split: "1"
      eval_params:
        strict_eval: true
        eval_interval: 50
        eval_batch_size: 1
        top_k: 1
        top_p: 0.4
        temperature: 0.8
